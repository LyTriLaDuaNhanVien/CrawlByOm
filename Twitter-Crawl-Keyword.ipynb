{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51fadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Script to Extract tweets of a\n",
    "# particular Hashtag using Tweepy and Pandas\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import pymongo\n",
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "    print()\n",
    "    print(f\"Tweet {n}:\")\n",
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    "\n",
    "    # Creating DataFrame using pandas\n",
    "    db = pd.DataFrame(columns=['username',\n",
    "                            'text',\n",
    "                            'description',\n",
    "                            'location',\n",
    "                            'following',\n",
    "                            'followers',\n",
    "                            'totaltweets',\n",
    "                            'favoritecount',\n",
    "                            'retweetcount',\n",
    "                            'hashtags',\n",
    "                            'created_at',\n",
    "                            'id_str'])\n",
    "\n",
    "    # We are using .Cursor() to search\n",
    "    # through twitter for the required tweets.\n",
    "    # The number of tweets can be\n",
    "    # restricted using .items(number of tweets)\n",
    "    tweets = tweepy.Cursor(api.search_tweets,\n",
    "                        words,\n",
    "                        since_id=date_since,\n",
    "                        tweet_mode='extended').items(numtweet)\n",
    "\n",
    "\n",
    "    # .Cursor() returns an iterable object. Each item in\n",
    "    # the iterator has various attributes\n",
    "    # that you can access to\n",
    "    # get information about each tweet\n",
    "    list_tweets = [tweet for tweet in tweets]\n",
    "\n",
    "    # Counter to maintain Tweet Count\n",
    "    i = 1\n",
    "\n",
    "    # we will iterate over each tweet in the\n",
    "    # list for extracting information about each tweet\n",
    "    for tweet in list_tweets:\n",
    "            username = tweet.user.screen_name\n",
    "            description = tweet.user.description\n",
    "            location = tweet.user.location\n",
    "            following = tweet.user.friends_count\n",
    "            followers = tweet.user.followers_count\n",
    "            totaltweets = tweet.user.statuses_count\n",
    "            favorite_count=tweet.favorite_count\n",
    "            retweetcount = tweet.retweet_count\n",
    "            hashtags = tweet.entities['hashtags']\n",
    "            created_at =  tweet.created_at\n",
    "            id_str =  tweet.id_str\n",
    "            # Retweets can be distinguished by\n",
    "            # a retweeted_status attribute,\n",
    "            # in case it is an invalid reference,\n",
    "            # except block will be executed\n",
    "            try:\n",
    "                    text = tweet.retweeted_status.full_text\n",
    "            except AttributeError:\n",
    "                    text = tweet.full_text\n",
    "            hashtext = list()\n",
    "            for j in range(0, len(hashtags)):\n",
    "                    hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "            # Here we are appending all the\n",
    "            # extracted information in the DataFrame\n",
    "            ith_tweet = [username, text, description,\n",
    "                        location, following,\n",
    "                        followers, totaltweets,favorite_count,\n",
    "                        retweetcount, hashtext,created_at,\n",
    "                        id_str]\n",
    "            db.loc[len(db)] = ith_tweet\n",
    "            post={'id':tweet.id_str,'Titlle':'null','Content':tweet.full_text,'CreatedDate':tweet.created_at,'Location':'null','Link':'https://twitter.com/'+tweet.user.screen_name+'/status/'+tweet.id_str,'TypeID':om,\"TypeIDText\":abc,'Enviroment':\"2\"}\n",
    "            collection.insert_one(post)\n",
    "            # Function call to print tweet data on screen\n",
    "            printtweetdata(i, ith_tweet)\n",
    "            i = i+1\n",
    "            \n",
    "    filename = '#'+words+'.csv'\n",
    "\n",
    "    # we will save our database as a CSV file.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    consumer_key = \"\"\n",
    "    consumer_secret = \"\"\n",
    "    access_token = \"\"\n",
    "    access_token_secret = \"\"\n",
    "#     consumer_key = \"\"\n",
    "#     consumer_secret = \"\"\n",
    "#     access_token = \"\"\n",
    "#     access_token_secret = \"\"\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)#\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # Enter Hashtag and initial date\n",
    "    words = input()\n",
    "    print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "    date_since = input()\n",
    "    #mongoDB insert\n",
    "    CONNECTION_STRING='YourString'\n",
    "    client = pymongo.MongoClient(CONNECTION_STRING)\n",
    "    db= client[\"demotw\"]\n",
    "    collection= db['demo']\n",
    "    # number of tweets you want to extract in one run\n",
    "    numtweet = 1000\n",
    "    scrape(words, date_since, numtweet)\n",
    "    print('Scraping has completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
